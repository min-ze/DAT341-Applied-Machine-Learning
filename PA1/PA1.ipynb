{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA1\n",
    "#### Applied Machine Learning\n",
    "Grpup 39: Sebastian KÃ¶lbel & Min Ze Teh\n",
    "## Task1\n",
    "We begin by using the code provided in the assignment to transform the data in the csv file into a panda dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# Read the CSV file.\n",
    "data = pd.read_csv('CTG.csv', skiprows=1)\n",
    "\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "\n",
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When choosing three classifiers we decided to pick one classifier form each of the different sub categories. We picked gradient boosting classifier and attempted to optimize it in terms of max depth, trying out different depths we found that we got the best performance when having a max depth of 5 or 6.\n",
    "\n",
    "For the Multi-layer perceptron classfier we tried adjusting the hidden_layer_sizes and found that we got the best accuracy when using the input value 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting classifier accuracy : 0.95\n",
      "Perceptron accuracy: 0.825294117647059\n",
      "MLP Classifier accuracy: 0.8841176470588236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "from sklearn.linear_model import Perceptron as perc\n",
    "from sklearn.neural_network import MLPClassifier as mlpc\n",
    "\n",
    "gbc_clf = gbc(max_depth=5,random_state=1)\n",
    "perc_clf = perc() \n",
    "mlpc_clf = mlpc(random_state= 1, hidden_layer_sizes=75)\n",
    "\n",
    "print('Gradient boosting classifier accuracy :', cross_val_score(gbc_clf, Xtrain, Ytrain).mean())\n",
    "print('Perceptron accuracy:', cross_val_score(perc_clf, Xtrain, Ytrain).mean())\n",
    "print('MLP Classifier accuracy:', cross_val_score(mlpc_clf, Xtrain, Ytrain).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final evaluation we picked the classifier that we found to have the best accuracy, namely the gradient boosting classifier. we fit the values and performed the prediction the resulting accuracy can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting classifier accuracy:  0.931924882629108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gbc_clf.fit(Xtrain, Ytrain)\n",
    "Yguess = gbc_clf.predict(Xtest)\n",
    "print('Gradient boosting classifier accuracy: ',accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeLeaf:\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    # This method computes the prediction for this leaf node. This will just return a constant value.\n",
    "    def predict(self, x):\n",
    "        return self.value\n",
    "\n",
    "    # Utility function to draw a tree visually using graphviz.\n",
    "    def draw_tree(self, graph, node_counter, names):\n",
    "        node_id = str(node_counter)\n",
    "        val_str = f'{self.value:.4g}' if isinstance(self.value, float) else str(self.value)\n",
    "        graph.node(node_id, val_str, style='filled')\n",
    "        return node_counter+1, node_id\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, DecisionTreeLeaf):\n",
    "            return self.value == other.value\n",
    "        else:\n",
    "            return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
