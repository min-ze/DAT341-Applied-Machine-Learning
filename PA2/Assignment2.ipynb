{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA2 Random forests\n",
    "#### Applied Machine Learning\n",
    "Grpup 39: Sebastian KÃ¶lbel & Min Ze Teh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1\n",
    "We begin by importing the testing and training csv files using pandas and dividing the sets into input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('Data/adult_train.csv')\n",
    "X_train = training.drop('target', axis=1)\n",
    "Y_train = training['target']\n",
    "\n",
    "testing = pd.read_csv('Data/adult_test.csv')\n",
    "X_test = testing.drop('target', axis=1)\n",
    "Y_test = testing['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the classifiers in sklearn we first have to make our input values into numerical values.\n",
    "The way used here is one-hot encoding, which we performed by first making our input into dictionaries and then running the dictionaries into the imported function DictVectorizer(). We picked gradient boosting classfier as it was one of the top performing classifiers in the previous assignment. However, as the data is different this time around, this might no longer be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting classifier cross_val_score: 0.871564280246915\n",
      "Gradient boosting classifier accuracy:  0.8740863583317978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create dictionaries of our train and testing input data.\n",
    "dicts_for_my_training_data = X_train.to_dict('records')\n",
    "dicts_for_my_test_data = X_test.to_dict('records')\n",
    "\n",
    "# Creating matrix from dictionaries\n",
    "dv = DictVectorizer()\n",
    "X_train_encoded = dv.fit_transform(dicts_for_my_training_data)\n",
    "X_test_encoded = dv.transform(dicts_for_my_test_data)\n",
    "\n",
    "# Picking gradient boosting classifier and performing cross validation\n",
    "gbc_clf = gbc(max_depth=5,random_state=1)\n",
    "print('Gradient boosting classifier cross_val_score:', cross_val_score(gbc_clf, X_train_encoded, Y_train).mean())\n",
    "\n",
    "# Testing accuracy of the classifier\n",
    "gbc_clf.fit(X_train_encoded, Y_train)\n",
    "Y_guess = gbc_clf.predict(X_test_encoded)\n",
    "\n",
    "print('Gradient boosting classifier accuracy: ',accuracy_score(Y_test, Y_guess))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then created a pipeline using the same steps as in the previous cell, but sequentially using make_pipeline(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    gbc(max_depth=5, random_state=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a quick test to see that the pipeline works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test:  0.8740863583317978\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(dicts_for_my_training_data, Y_train)\n",
    "Y_guess2 = pipeline.predict(dicts_for_my_test_data)\n",
    "print('accuracy test: ',accuracy_score(Y_test, Y_guess2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
